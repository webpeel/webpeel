<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <meta property="og:image" content="https://webpeel.dev/og-image.png">
  <meta name="twitter:image" content="https://webpeel.dev/og-image.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:creator" content="@webpeel_dev">
  <link rel="icon" href="/favicon.ico" sizes="32x32">
  <link rel="icon" href="/favicon.svg" type="image/svg+xml">
  <link rel="apple-touch-icon" href="/apple-touch-icon.png">
  <meta name="description" content="WebPeel CLI reference — fetch, search, crawl, and extract web content from your terminal.">
  <link rel="canonical" href="https://webpeel.dev/docs/cli">
  <meta property="og:title" content="CLI Reference — WebPeel">
  <meta property="og:description" content="WebPeel CLI reference — fetch, search, crawl, and extract web content from your terminal.">
  <meta property="og:url" content="https://webpeel.dev/docs/cli">
  <meta property="og:type" content="website">
  <title>CLI Reference — WebPeel</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Instrument+Serif:ital@0;1&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
  <link rel="stylesheet" href="../styles/docs.css">
</head>
<body>
  <nav class="docs-nav">
    <div class="container nav-inner">
      <a href="/" class="nav-logo">
        <svg viewBox="0 0 32 32"><rect width="32" height="32" fill="#8B5CF6" rx="7"/><path d="M6 3h14l7 7v18a3 3 0 01-3 3H6a3 3 0 01-3-3V6a3 3 0 013-3z" fill="#FFF" fill-opacity=".95"/><path d="M20 3v5a2 2 0 002 2h5" fill="#DDD6FE"/><path d="M8 16h10" stroke="#8B5CF6" stroke-width="2.5" stroke-linecap="round"/><path d="M8 21h14" stroke="#A78BFA" stroke-width="2.5" stroke-linecap="round"/></svg>
        WebPeel
      </a>
      <div class="nav-links">
        <a href="/#how">How It Works</a>
        <a href="/playground">Playground</a>
        <a href="/#compare">Compare</a>
        <a href="/#pricing">Pricing</a>
        <a href="/blog/">Blog</a>
        <a href="/changelog">Changelog</a>
        <a href="/docs/">Docs</a>
        <a href="https://app.webpeel.dev" class="nav-btn nav-btn-ghost">Dashboard</a>
        <a href="https://app.webpeel.dev/signup" class="nav-btn nav-btn-primary">Get Started</a>
      </div>
    </div>
  </nav>

  <div class="docs-layout">
    <aside class="sidebar">
      <div class="sidebar-section">
        <div class="sidebar-title">Getting Started</div>
        <a href="/docs/" class="sidebar-link">Overview</a>
        <a href="/docs/api-reference" class="sidebar-link">API Reference</a>
      </div>
      
      <div class="sidebar-section">
        <div class="sidebar-title">SDKs</div>
        <a href="/docs/sdks" class="sidebar-link">Node.js & Python</a>
        <a href="/docs/cli" class="sidebar-link active">CLI</a>
        <a href="/docs/mcp" class="sidebar-link">MCP Server</a>
      </div>
      
      <div class="sidebar-section">
        <div class="sidebar-title">Deployment</div>
        <a href="/docs/self-hosting" class="sidebar-link">Self-Hosting</a>
      </div>
    </aside>

    <main class="docs-content">
      <div class="breadcrumbs">
        <a href="/docs/">Documentation</a>
        <span>/</span>
        <span>CLI</span>
      </div>

      <h1>CLI Reference</h1>
      <p class="lead">Command-line interface for WebPeel. 20+ commands for web scraping, searching, crawling, and hotel search.</p>

      <h2>Installation</h2>
      <pre><code class="language-bash">npm install -g webpeel</code></pre>

      <h2>Quick Start</h2>
      <pre><code class="language-bash"># Fetch a URL
npx webpeel https://example.com

# Output as JSON
npx webpeel https://example.com --json

# Use browser rendering
npx webpeel https://example.com --render

# Search the web (DuckDuckGo default)
npx webpeel search "AI news"

# Search with Brave (BYOK)
npx webpeel search "AI news" --provider brave --search-api-key $BRAVE_KEY

# Get a cited answer (BYOK)
npx webpeel answer "What is MCP?" --llm openai --llm-api-key $OPENAI_API_KEY

# v0.10.0: CSS schema extraction (auto-detected by domain)
npx webpeel https://www.amazon.com/s?k=keyboard --json
npx webpeel https://news.ycombinator.com --schema hn --json
npx webpeel --list-schemas

# v0.10.0: LLM extraction (BYOK)
npx webpeel https://example.com/product --llm-extract "title, price, rating" --json

# v0.10.0: Hotel search
npx webpeel hotels "Paris" --checkin 2026-03-01 --checkout 2026-03-05 --sort price

# v0.10.0: Browser profiles
npx webpeel profile create myprofile
npx webpeel https://example.com --profile myprofile --stealth</code></pre>

      <h2>Global Options</h2>
      <table>
        <thead>
          <tr>
            <th>Option</th>
            <th>Description</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td><code>-s, --silent</code></td>
            <td>Silent mode (no spinner, no progress)</td>
          </tr>
          <tr>
            <td><code>--json</code></td>
            <td>Output as JSON</td>
          </tr>
          <tr>
            <td><code>-h, --help</code></td>
            <td>Show help</td>
          </tr>
          <tr>
            <td><code>-V, --version</code></td>
            <td>Show version number</td>
          </tr>
        </tbody>
      </table>

      <h2>Commands</h2>

      <h3><code>webpeel &lt;url&gt;</code></h3>
      <p>Fetch and extract content from a URL.</p>

      <pre><code class="language-bash"># Basic usage
npx webpeel https://example.com

# Output formats
npx webpeel https://example.com --html
npx webpeel https://example.com --text
npx webpeel https://example.com --json

# Browser rendering
npx webpeel https://example.com --render
npx webpeel https://example.com --stealth
npx webpeel https://example.com --wait 5000

# Content filtering
npx webpeel https://example.com --selector "article"
npx webpeel https://example.com --exclude ".sidebar" ".ads"
npx webpeel https://example.com --only-main-content

# Advanced options
npx webpeel https://example.com --screenshot
npx webpeel https://example.com --screenshot screenshot.png
npx webpeel https://example.com --full-page
npx webpeel https://example.com --max-tokens 5000
npx webpeel https://example.com --cache 1h

# v0.9.0: Agent mode (JSON + budget + extraction + silent)
npx webpeel https://example.com --agent

# v0.9.0: Auto-extract listings (product cards, search results)
npx webpeel https://example.com --extract-all
npx webpeel https://example.com --extract-all --table
npx webpeel https://example.com --extract-all --csv

# v0.9.0: Token budget
npx webpeel https://example.com --budget 4000

# v0.10.0: CSS schema extraction
npx webpeel https://www.amazon.com/s?k=laptop --schema amazon --json
npx webpeel --list-schemas

# v0.10.0: LLM extraction (BYOK — uses OPENAI_API_KEY / WEBPEEL_LLM_BASE_URL)
npx webpeel https://example.com/product --llm-extract "title, price, in-stock" --json
npx webpeel https://example.com --llm-extract --json

# v0.10.0: Browser profile
npx webpeel https://example.com --profile myprofile</code></pre>

      <h4>Options</h4>
      <table>
        <thead>
          <tr>
            <th>Option</th>
            <th>Type</th>
            <th>Description</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td><code>--html</code></td>
            <td>boolean</td>
            <td>Output raw HTML</td>
          </tr>
          <tr>
            <td><code>--text</code></td>
            <td>boolean</td>
            <td>Output plain text</td>
          </tr>
          <tr>
            <td><code>-r, --render</code></td>
            <td>boolean</td>
            <td>Use headless browser</td>
          </tr>
          <tr>
            <td><code>--stealth</code></td>
            <td>boolean</td>
            <td>Use stealth mode</td>
          </tr>
          <tr>
            <td><code>-w, --wait &lt;ms&gt;</code></td>
            <td>number</td>
            <td>Wait time after page load (ms)</td>
          </tr>
          <tr>
            <td><code>--selector &lt;css&gt;</code></td>
            <td>string</td>
            <td>CSS selector to extract</td>
          </tr>
          <tr>
            <td><code>--exclude &lt;selectors...&gt;</code></td>
            <td>string[]</td>
            <td>CSS selectors to exclude</td>
          </tr>
          <tr>
            <td><code>--include-tags &lt;tags&gt;</code></td>
            <td>string</td>
            <td>Comma-separated tags to include</td>
          </tr>
          <tr>
            <td><code>--exclude-tags &lt;tags&gt;</code></td>
            <td>string</td>
            <td>Comma-separated tags to exclude</td>
          </tr>
          <tr>
            <td><code>--only-main-content</code></td>
            <td>boolean</td>
            <td>Extract only main/article content</td>
          </tr>
          <tr>
            <td><code>--screenshot [path]</code></td>
            <td>string</td>
            <td>Capture screenshot (optional path)</td>
          </tr>
          <tr>
            <td><code>--full-page</code></td>
            <td>boolean</td>
            <td>Full-page screenshot</td>
          </tr>
          <tr>
            <td><code>--links</code></td>
            <td>boolean</td>
            <td>Output only links</td>
          </tr>
          <tr>
            <td><code>--images</code></td>
            <td>boolean</td>
            <td>Output image URLs</td>
          </tr>
          <tr>
            <td><code>--meta</code></td>
            <td>boolean</td>
            <td>Output only metadata</td>
          </tr>
          <tr>
            <td><code>--max-tokens &lt;n&gt;</code></td>
            <td>number</td>
            <td>Max token count (truncate)</td>
          </tr>
          <tr>
            <td><code>--cache &lt;ttl&gt;</code></td>
            <td>string</td>
            <td>Cache TTL (e.g., "5m", "1h", "1d")</td>
          </tr>
          <tr>
            <td><code>--location &lt;country&gt;</code></td>
            <td>string</td>
            <td>ISO country code</td>
          </tr>
          <tr>
            <td><code>--language &lt;lang&gt;</code></td>
            <td>string</td>
            <td>Language preference</td>
          </tr>
          <tr>
            <td><code>--agent</code></td>
            <td>boolean</td>
            <td>Agent mode: sets --json, --silent, --extract-all, --budget 4000 <span class="badge">v0.9.0</span></td>
          </tr>
          <tr>
            <td><code>--extract-all</code></td>
            <td>boolean</td>
            <td>Auto-detect and extract repeated listings (product cards, search results) <span class="badge">v0.9.0</span></td>
          </tr>
          <tr>
            <td><code>--budget &lt;n&gt;</code></td>
            <td>number</td>
            <td>Smart token budget — distill content to fit within N tokens <span class="badge">v0.9.0</span></td>
          </tr>
          <tr>
            <td><code>--table</code></td>
            <td>boolean</td>
            <td>Output extracted listings as a formatted table <span class="badge">v0.9.0</span></td>
          </tr>
          <tr>
            <td><code>--csv</code></td>
            <td>boolean</td>
            <td>Output extracted listings as CSV <span class="badge">v0.9.0</span></td>
          </tr>
          <tr>
            <td><code>--pages &lt;n&gt;</code></td>
            <td>number</td>
            <td>Multi-page pagination (1-10) <span class="badge">v0.9.0</span></td>
          </tr>
          <tr>
            <td><code>--scroll-extract [n]</code></td>
            <td>number</td>
            <td>Infinite scroll extraction <span class="badge">v0.9.0</span></td>
          </tr>
          <tr>
            <td><code>--schema &lt;name&gt;</code></td>
            <td>string</td>
            <td>Apply a CSS extraction schema (e.g. <code>amazon</code>, <code>booking</code>, <code>ebay</code>, <code>yelp</code>, <code>walmart</code>, <code>hn</code>). Auto-detected by domain if omitted. <span class="badge">v0.10.0</span></td>
          </tr>
          <tr>
            <td><code>--list-schemas</code></td>
            <td>boolean</td>
            <td>List all bundled CSS extraction schemas and exit <span class="badge">v0.10.0</span></td>
          </tr>
          <tr>
            <td><code>--llm-extract [instruction]</code></td>
            <td>string</td>
            <td>Extract structured data using an LLM (BYOK). Optional natural-language instruction, e.g. <code>"title, price, rating"</code>. Uses <code>WEBPEEL_LLM_BASE_URL</code> / <code>OPENAI_API_KEY</code>. <span class="badge">v0.10.0</span></td>
          </tr>
          <tr>
            <td><code>--profile &lt;name&gt;</code></td>
            <td>string</td>
            <td>Load a saved browser profile (cookies, localStorage, auth). Create profiles with <code>webpeel profile create</code>. <span class="badge">v0.10.0</span></td>
          </tr>
        </tbody>
      </table>

      <h3><code>webpeel search &lt;query&gt;</code></h3>
      <p>Search the web using DuckDuckGo (default, free) or Brave Search (BYOK). New in v0.9.0: use <code>--site</code> to search specific sites with auto-extraction.</p>

      <pre><code class="language-bash"># Basic search (DuckDuckGo)
npx webpeel search "AI news"

# Use Brave Search (BYOK)
npx webpeel search "AI news" --provider brave --search-api-key $BRAVE_KEY

# Or set once in config
npx webpeel config set braveApiKey $BRAVE_KEY
npx webpeel search "AI news" --provider brave

# Limit results
npx webpeel search "python tutorials" -n 10

# JSON output
npx webpeel search "web scraping" --json

# v0.9.0: Site-specific search (no URL knowledge needed!)
npx webpeel search --site ebay "charizard card"
npx webpeel search --site amazon "mechanical keyboard" --json
npx webpeel search --site walmart "ps5" --table
npx webpeel search --site github "web scraper typescript"

# List all supported sites
npx webpeel sites</code></pre>

      <h4>Options</h4>
      <table>
        <thead>
          <tr>
            <th>Option</th>
            <th>Description</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td><code>-n, --count &lt;n&gt;</code></td>
            <td>Number of results (1-10, default: 5)</td>
          </tr>
          <tr>
            <td><code>--provider &lt;provider&gt;</code></td>
            <td>Search provider: <code>duckduckgo</code> (default) or <code>brave</code></td>
          </tr>
          <tr>
            <td><code>--search-api-key &lt;key&gt;</code></td>
            <td>Brave Search API key (or env <code>WEBPEEL_BRAVE_API_KEY</code>)</td>
          </tr>
          <tr>
            <td><code>--site &lt;site&gt;</code></td>
            <td>Search a specific site (e.g. <code>ebay</code>, <code>amazon</code>, <code>github</code>). Run <code>webpeel sites</code> for full list. <span class="badge">v0.9.0</span></td>
          </tr>
          <tr>
            <td><code>--json</code></td>
            <td>Output as JSON</td>
          </tr>
          <tr>
            <td><code>--table</code></td>
            <td>Output site-search results as a formatted table <span class="badge">v0.9.0</span></td>
          </tr>
          <tr>
            <td><code>--csv</code></td>
            <td>Output site-search results as CSV <span class="badge">v0.9.0</span></td>
          </tr>
          <tr>
            <td><code>--profile &lt;name&gt;</code></td>
            <td>Load a saved browser profile for site-aware searches <span class="badge">v0.10.0</span></td>
          </tr>
          <tr>
            <td><code>-s, --silent</code></td>
            <td>Silent mode</td>
          </tr>
        </tbody>
      </table>

      <h3><code>webpeel sites</code> <span class="badge">v0.9.0</span></h3>
      <p>List all supported sites for site-aware search. 27 sites across 7 categories: shopping, general, social, tech, jobs, real-estate, food.</p>
      <pre><code class="language-bash"># List all sites
npx webpeel sites

# Filter by category
npx webpeel sites --category shopping

# JSON output
npx webpeel sites --json</code></pre>

      <h3><code>webpeel answer &lt;question&gt;</code></h3>
      <p>Ask a question, search the web, fetch sources, and get an AI-generated answer with citations. BYOK — bring your own LLM API key.</p>

      <pre><code class="language-bash"># Answer with citations (DuckDuckGo search by default)
npx webpeel answer "What is MCP?" --llm openai --llm-api-key $OPENAI_API_KEY

# Use Brave Search for higher-quality results (BYOK)
npx webpeel answer "What is MCP?" \
  --provider brave \
  --search-api-key $BRAVE_KEY \
  --llm anthropic \
  --llm-api-key $ANTHROPIC_API_KEY \
  --max-sources 5

# JSON output
npx webpeel answer "Compare DuckDuckGo vs Brave Search" \
  --llm openai --llm-api-key $OPENAI_API_KEY \
  --json</code></pre>

      <h4>Options</h4>
      <table>
        <thead>
          <tr>
            <th>Option</th>
            <th>Description</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td><code>--provider &lt;provider&gt;</code></td>
            <td>Search provider: <code>duckduckgo</code> (default) or <code>brave</code></td>
          </tr>
          <tr>
            <td><code>--search-api-key &lt;key&gt;</code></td>
            <td>Brave Search API key (or env <code>WEBPEEL_BRAVE_API_KEY</code>)</td>
          </tr>
          <tr>
            <td><code>--llm &lt;provider&gt;</code></td>
            <td>LLM provider: <code>openai</code>, <code>anthropic</code>, or <code>google</code></td>
          </tr>
          <tr>
            <td><code>--llm-api-key &lt;key&gt;</code></td>
            <td>LLM API key (or env <code>OPENAI_API_KEY</code> / <code>ANTHROPIC_API_KEY</code> / <code>GOOGLE_API_KEY</code>)</td>
          </tr>
          <tr>
            <td><code>--llm-model &lt;model&gt;</code></td>
            <td>Optional LLM model name (provider-specific)</td>
          </tr>
          <tr>
            <td><code>--max-sources &lt;n&gt;</code></td>
            <td>Maximum sources to fetch (1-10, default: 5)</td>
          </tr>
          <tr>
            <td><code>--json</code></td>
            <td>Output as JSON</td>
          </tr>
          <tr>
            <td><code>-s, --silent</code></td>
            <td>Silent mode</td>
          </tr>
        </tbody>
      </table>

      <h3><code>webpeel batch [file]</code></h3>
      <p>Fetch multiple URLs from file or stdin.</p>

      <pre><code class="language-bash"># From file
npx webpeel batch urls.txt

# From stdin
cat urls.txt | npx webpeel batch

# With concurrency
npx webpeel batch urls.txt -c 5

# Save to directory
npx webpeel batch urls.txt -o output/

# JSON output
npx webpeel batch urls.txt --json</code></pre>

      <h4>Options</h4>
      <table>
        <thead>
          <tr>
            <th>Option</th>
            <th>Description</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td><code>-c, --concurrency &lt;n&gt;</code></td>
            <td>Max concurrent fetches (default: 3)</td>
          </tr>
          <tr>
            <td><code>-o, --output &lt;dir&gt;</code></td>
            <td>Output directory (one file per URL)</td>
          </tr>
          <tr>
            <td><code>--json</code></td>
            <td>Output as JSON array</td>
          </tr>
          <tr>
            <td><code>-r, --render</code></td>
            <td>Use browser rendering for all</td>
          </tr>
          <tr>
            <td><code>--selector &lt;css&gt;</code></td>
            <td>CSS selector to extract</td>
          </tr>
        </tbody>
      </table>

      <h3><code>webpeel crawl &lt;url&gt;</code></h3>
      <p>Crawl a website recursively.</p>

      <pre><code class="language-bash"># Basic crawl
npx webpeel crawl https://example.com

# Limit pages and depth
npx webpeel crawl https://example.com --max-pages 100 --max-depth 3

# Exclude patterns
npx webpeel crawl https://example.com --exclude "/admin/" "/login"

# Domain restrictions
npx webpeel crawl https://example.com --allowed-domains "example.com" "docs.example.com"

# Ignore robots.txt
npx webpeel crawl https://example.com --ignore-robots

# With browser rendering
npx webpeel crawl https://example.com --render --stealth</code></pre>

      <h4>Options</h4>
      <table>
        <thead>
          <tr>
            <th>Option</th>
            <th>Description</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td><code>--max-pages &lt;n&gt;</code></td>
            <td>Max pages to crawl (default: 10, max: 100)</td>
          </tr>
          <tr>
            <td><code>--max-depth &lt;n&gt;</code></td>
            <td>Max depth (default: 2, max: 5)</td>
          </tr>
          <tr>
            <td><code>--allowed-domains &lt;domains...&gt;</code></td>
            <td>Only crawl these domains</td>
          </tr>
          <tr>
            <td><code>--exclude &lt;patterns...&gt;</code></td>
            <td>Exclude URL patterns (regex)</td>
          </tr>
          <tr>
            <td><code>--ignore-robots</code></td>
            <td>Ignore robots.txt</td>
          </tr>
          <tr>
            <td><code>--rate-limit &lt;ms&gt;</code></td>
            <td>Rate limit (default: 1000ms)</td>
          </tr>
          <tr>
            <td><code>-r, --render</code></td>
            <td>Use browser rendering</td>
          </tr>
          <tr>
            <td><code>--stealth</code></td>
            <td>Use stealth mode</td>
          </tr>
        </tbody>
      </table>

      <h3><code>webpeel map &lt;url&gt;</code></h3>
      <p>Discover all URLs on a domain.</p>

      <pre><code class="language-bash"># Map a domain
npx webpeel map https://example.com

# Skip sitemap
npx webpeel map https://example.com --no-sitemap

# Skip crawl
npx webpeel map https://example.com --no-crawl

# Limit results
npx webpeel map https://example.com --max 1000

# Filter patterns
npx webpeel map https://example.com --include "/docs/" --exclude "/api/"</code></pre>

      <h4>Options</h4>
      <table>
        <thead>
          <tr>
            <th>Option</th>
            <th>Description</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td><code>--no-sitemap</code></td>
            <td>Skip sitemap.xml discovery</td>
          </tr>
          <tr>
            <td><code>--no-crawl</code></td>
            <td>Skip homepage crawl</td>
          </tr>
          <tr>
            <td><code>--max &lt;n&gt;</code></td>
            <td>Max URLs (default: 5000)</td>
          </tr>
          <tr>
            <td><code>--include &lt;patterns...&gt;</code></td>
            <td>Include URL patterns (regex)</td>
          </tr>
          <tr>
            <td><code>--exclude &lt;patterns...&gt;</code></td>
            <td>Exclude URL patterns (regex)</td>
          </tr>
        </tbody>
      </table>

      <h3><code>webpeel login</code></h3>
      <p>Authenticate CLI with API key.</p>

      <pre><code class="language-bash">npx webpeel login
# Prompts for API key, saves to ~/.webpeel/config.json</code></pre>

      <h3><code>webpeel logout</code></h3>
      <p>Clear saved credentials.</p>

      <pre><code class="language-bash">npx webpeel logout</code></pre>

      <h3><code>webpeel whoami</code></h3>
      <p>Show authentication status.</p>

      <pre><code class="language-bash">npx webpeel whoami
# Logged in with API key: sk-1234...abcd
# Plan: Pro
# Config: ~/.webpeel/config.json</code></pre>

      <h3><code>webpeel usage</code></h3>
      <p>Show usage and quota.</p>

      <pre><code class="language-bash">npx webpeel usage
# Free: 45/125 fetches this week (36%)
# Resets: Mon Feb 17 2026 00:00:00 EST</code></pre>

      <h3><code>webpeel config [action] [key] [value]</code></h3>
      <p>View or update CLI configuration (stored in <code>~/.webpeel/config.json</code>).</p>

      <pre><code class="language-bash"># Show overview
npx webpeel config

# Get specific key
npx webpeel config get braveApiKey

# Set Brave Search API key (BYOK)
npx webpeel config set braveApiKey $BRAVE_KEY</code></pre>

      <h3><code>webpeel cache &lt;action&gt;</code></h3>
      <p>Manage local response cache.</p>

      <pre><code class="language-bash"># Show cache stats
npx webpeel cache stats

# Clear expired entries
npx webpeel cache clear

# Purge all entries
npx webpeel cache purge</code></pre>

      <h3><code>webpeel serve</code></h3>
      <p>Start API server.</p>

      <pre><code class="language-bash"># Default port 3000
npx webpeel serve

# Custom port
npx webpeel serve -p 8080</code></pre>

      <h3><code>webpeel mcp</code></h3>
      <p>Start MCP server for Claude/Cursor.</p>

      <pre><code class="language-bash">npx webpeel mcp
# Runs on stdio for Claude Desktop / Cursor integration</code></pre>

      <h3><code>webpeel research &lt;query&gt;</code></h3>
      <p>Multi-source deep research with BM25 relevance ranking. No LLM key needed for sources mode.</p>

      <pre><code class="language-bash"># Get ranked sources with relevance scores
npx webpeel research "best web scraping tools 2025" --max-sources 5

# Full synthesis with LLM
npx webpeel research "compare Firecrawl vs Crawl4AI" --llm-key $OPENAI_API_KEY

# JSON output
npx webpeel research "AI trends" --format sources --json</code></pre>

      <table>
        <tr><th>Flag</th><th>Description</th><th>Default</th></tr>
        <tr><td><code>--max-sources</code></td><td>Max sources to fetch</td><td>5</td></tr>
        <tr><td><code>--max-depth</code></td><td>Link-following depth (1=no follow)</td><td>2</td></tr>
        <tr><td><code>--format</code></td><td><code>report</code> (LLM synthesis) or <code>sources</code> (raw)</td><td>report</td></tr>
        <tr><td><code>--timeout</code></td><td>Total timeout in ms</td><td>60000</td></tr>
        <tr><td><code>--llm-key</code></td><td>OpenAI API key for synthesis</td><td>—</td></tr>
        <tr><td><code>--llm-model</code></td><td>Model for synthesis</td><td>gpt-4o-mini</td></tr>
      </table>

      <h3>Token Efficiency Flags</h3>
      <p>Save 15-77% on AI tokens. These flags work with any fetch command.</p>

      <pre><code class="language-bash"># BM25 query-focused filtering — keep only relevant content
npx webpeel https://en.wikipedia.org/wiki/AI --focus "machine learning"

# Smart chunking — split into LLM-friendly pieces
npx webpeel https://example.com --chunk 2000 --chunk-strategy semantic

# Disable content pruning (on by default)
npx webpeel https://example.com --full-content

# Combined: prune → focus → budget = max savings
npx webpeel https://example.com --focus "pricing" --budget 3000</code></pre>

      <table>
        <tr><th>Flag</th><th>Description</th><th>Default</th></tr>
        <tr><td><code>--focus &lt;query&gt;</code></td><td>BM25 query filter — keeps relevant blocks only</td><td>—</td></tr>
        <tr><td><code>--chunk &lt;tokens&gt;</code></td><td>Split output into chunks of N tokens</td><td>—</td></tr>
        <tr><td><code>--chunk-strategy</code></td><td><code>semantic</code>, <code>fixed</code>, or <code>paragraph</code></td><td>semantic</td></tr>
        <tr><td><code>--chunk-overlap &lt;n&gt;</code></td><td>Overlap tokens between chunks</td><td>0</td></tr>
        <tr><td><code>--full-content</code></td><td>Disable content pruning</td><td>pruning ON</td></tr>
        <tr><td><code>--budget &lt;tokens&gt;</code></td><td>Hard token cap on output</td><td>—</td></tr>
      </table>

      <h3>Infinite Scroll</h3>
      <p>Automatically scroll to load all lazy content before extracting.</p>

      <pre><code class="language-bash"># Smart auto-scroll (detects when page stops growing)
npx webpeel https://example.com --scroll-extract

# Fixed number of scrolls
npx webpeel https://example.com --scroll-extract 10

# With timeout
npx webpeel https://example.com --scroll-extract --scroll-extract-timeout 15000</code></pre>

      <h3><code>webpeel agent &lt;prompt&gt;</code></h3>
      <p>Run autonomous web research agent (BYOK LLM).</p>

      <pre><code class="language-bash"># Basic agent
npx webpeel agent "Find the top 5 AI coding tools" --llm-key $OPENAI_API_KEY

# With schema
npx webpeel agent "Compare AI tools" \
  --llm-key $OPENAI_API_KEY \
  --schema '{"type":"array","items":{"properties":{"name":{"type":"string"}}}}'

# With starting URLs
npx webpeel agent "Extract pricing" \
  --urls https://example.com,https://example.org \
  --llm-key $OPENAI_API_KEY</code></pre>

      <h3><code>webpeel track &lt;url&gt;</code></h3>
      <p>Track content changes.</p>

      <pre><code class="language-bash">npx webpeel track https://example.com
# Returns fingerprint for change detection</code></pre>

      <h3><code>webpeel summarize &lt;url&gt;</code></h3>
      <p>Generate AI summary.</p>

      <pre><code class="language-bash">npx webpeel summarize https://example.com --llm-key $OPENAI_API_KEY

# Custom prompt
npx webpeel summarize https://example.com \
  --llm-key $OPENAI_API_KEY \
  --prompt "Summarize in 3 bullet points"</code></pre>

      <h3><code>webpeel brand &lt;url&gt;</code></h3>
      <p>Extract branding and design system.</p>

      <pre><code class="language-bash">npx webpeel brand https://example.com --json</code></pre>

      <h3><code>webpeel jobs</code></h3>
      <p>List active async jobs.</p>

      <pre><code class="language-bash">npx webpeel jobs --json</code></pre>

      <h3><code>webpeel job &lt;id&gt;</code></h3>
      <p>Get job status.</p>

      <pre><code class="language-bash">npx webpeel job crawl_abc123 --json</code></pre>

      <h3><code>webpeel profile &lt;action&gt; [name]</code> <span class="badge">v0.10.0</span></h3>
      <p>Manage persistent browser profiles. Profiles save cookies, localStorage, and auth state so you can reuse logged-in sessions across requests.</p>

      <pre><code class="language-bash"># Create a new profile
npx webpeel profile create myprofile

# List all saved profiles
npx webpeel profile list

# Show details for a specific profile
npx webpeel profile show myprofile

# Delete a profile
npx webpeel profile delete myprofile</code></pre>

      <p>Use a profile when fetching:</p>
      <pre><code class="language-bash"># Fetch using a saved profile (cookies + auth preserved)
npx webpeel https://example.com --profile myprofile --stealth

# Search using a profile
npx webpeel search --site amazon "laptop stand" --profile myprofile --json</code></pre>

      <h4>Subcommands</h4>
      <table>
        <thead>
          <tr>
            <th>Subcommand</th>
            <th>Description</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td><code>create &lt;name&gt;</code></td>
            <td>Create and initialize a new browser profile</td>
          </tr>
          <tr>
            <td><code>list</code></td>
            <td>List all saved profiles</td>
          </tr>
          <tr>
            <td><code>show &lt;name&gt;</code></td>
            <td>Show profile metadata (created date, domain list, cookie count)</td>
          </tr>
          <tr>
            <td><code>delete &lt;name&gt;</code></td>
            <td>Delete a saved profile</td>
          </tr>
        </tbody>
      </table>

      <h3><code>webpeel hotels &lt;destination&gt;</code> <span class="badge">v0.10.0</span></h3>
      <p>Search for hotels across multiple sources in parallel. Results are merged, deduplicated, and sorted. Expedia is supported thanks to Stealth v2.</p>

      <pre><code class="language-bash"># Basic hotel search
npx webpeel hotels "Paris"

# With check-in and check-out dates
npx webpeel hotels "New York" --checkin 2026-04-10 --checkout 2026-04-14

# Sort by price (cheapest first)
npx webpeel hotels "Tokyo" --checkin 2026-05-01 --checkout 2026-05-05 --sort price

# Sort by rating
npx webpeel hotels "London" --checkin 2026-06-01 --checkout 2026-06-03 --sort rating

# JSON output for AI agents
npx webpeel hotels "Barcelona" --checkin 2026-07-01 --checkout 2026-07-07 --json

# Limit results
npx webpeel hotels "Berlin" --checkin 2026-08-01 -n 10 --json</code></pre>

      <h4>Options</h4>
      <table>
        <thead>
          <tr>
            <th>Option</th>
            <th>Description</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td><code>--checkin &lt;date&gt;</code></td>
            <td>Check-in date in <code>YYYY-MM-DD</code> format</td>
          </tr>
          <tr>
            <td><code>--checkout &lt;date&gt;</code></td>
            <td>Check-out date in <code>YYYY-MM-DD</code> format</td>
          </tr>
          <tr>
            <td><code>--sort &lt;field&gt;</code></td>
            <td>Sort results: <code>price</code>, <code>rating</code>, or <code>relevance</code> (default)</td>
          </tr>
          <tr>
            <td><code>-n, --count &lt;n&gt;</code></td>
            <td>Max results to return (default: 10)</td>
          </tr>
          <tr>
            <td><code>--json</code></td>
            <td>Output as JSON array</td>
          </tr>
          <tr>
            <td><code>--table</code></td>
            <td>Output as formatted table</td>
          </tr>
          <tr>
            <td><code>-s, --silent</code></td>
            <td>Silent mode (no spinner)</td>
          </tr>
        </tbody>
      </table>

      <h2>Environment Variables</h2>
      <table>
        <thead>
          <tr>
            <th>Variable</th>
            <th>Description</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td><code>WEBPEEL_API_KEY</code></td>
            <td>API key for authentication</td>
          </tr>
          <tr>
            <td><code>OPENAI_API_KEY</code></td>
            <td>OpenAI API key for LLM features</td>
          </tr>
          <tr>
            <td><code>ANTHROPIC_API_KEY</code></td>
            <td>Anthropic API key for LLM features</td>
          </tr>
          <tr>
            <td><code>GOOGLE_API_KEY</code></td>
            <td>Google API key for Gemini / LLM features</td>
          </tr>
          <tr>
            <td><code>WEBPEEL_BRAVE_API_KEY</code></td>
            <td>Brave Search API key for <code>webpeel search</code> / <code>webpeel answer</code></td>
          </tr>
          <tr>
            <td><code>WEBPEEL_LLM_MODEL</code></td>
            <td>LLM model (default: gpt-4o-mini)</td>
          </tr>
          <tr>
            <td><code>WEBPEEL_LLM_BASE_URL</code></td>
            <td>LLM API base URL</td>
          </tr>
          <tr>
            <td><code>WEBPEEL_API_URL</code></td>
            <td>WebPeel API URL (self-hosted)</td>
          </tr>
        </tbody>
      </table>

      <h2>Examples</h2>

      <h3>Extract Product Data</h3>
      <pre><code class="language-bash">npx webpeel https://example.com/product \
  --extract '{"title": "h1", "price": ".price", "rating": ".stars"}' \
  --json</code></pre>

      <h3>Monitor Price Changes</h3>
      <pre><code class="language-bash">#!/bin/bash
URL="https://example.com/product"

# First run
FINGERPRINT=$(npx webpeel $URL --json | jq -r '.fingerprint')
echo $FINGERPRINT > fingerprint.txt

# Later runs
NEW_FP=$(npx webpeel $URL --json | jq -r '.fingerprint')
OLD_FP=$(cat fingerprint.txt)

if [ "$NEW_FP" != "$OLD_FP" ]; then
  echo "Price changed!"
fi</code></pre>

      <h3>Batch Download Documentation</h3>
      <pre><code class="language-bash"># Discover all docs URLs
npx webpeel map https://docs.example.com \
  --include "/docs/" \
  --json > urls.json

# Extract URLs
cat urls.json | jq -r '.urls[]' > urls.txt

# Batch download
npx webpeel batch urls.txt -o docs/ --selector "article"</code></pre>

      <h2 id="mcp-server">MCP Server</h2>
      <p>WebPeel exposes an <a href="https://modelcontextprotocol.io" target="_blank">MCP (Model Context Protocol)</a> server so AI assistants like Claude, Cursor, and Windsurf can fetch, search, and crawl the web on your behalf.</p>

      <h3>Remote URL — No Install Needed</h3>
      <p>The fastest way to connect. Paste this into your AI client's MCP config — no <code>npm install</code> required:</p>
      <pre><code class="language-json">{
  "mcpServers": {
    "webpeel": {
      "url": "https://api.webpeel.dev/v2/mcp",
      "headers": {
        "Authorization": "Bearer YOUR-API-KEY"
      }
    }
  }
}</code></pre>
      <p>Or use the Firecrawl-style key-in-URL format (works with clients that don't support custom headers):</p>
      <pre><code class="language-json">{
  "mcpServers": {
    "webpeel": {
      "url": "https://api.webpeel.dev/YOUR-API-KEY/v2/mcp"
    }
  }
}</code></pre>

      <h3>One-Click Install for Cursor</h3>
      <p>
        <a href="cursor://anysphere.cursor-deeplink/mcp/install?name=webpeel&config=eyJjb21tYW5kIjoibnB4IiwiYXJncyI6WyIteSIsIndlYnBlZWwiLCItLW1jcCJdLCJlbnYiOnsiV0VCUEVFTF9BUElfS0VZIjoiWU9VUi1BUEktS0VZIn19"
           style="display:inline-block;padding:8px 16px;background:#5865F2;color:#fff;border-radius:6px;text-decoration:none;font-weight:600;">
          ➕ Add WebPeel to Cursor
        </a>
      </p>
      <p>After clicking, replace <code>YOUR-API-KEY</code> in Cursor's MCP settings with your actual key from <a href="https://app.webpeel.dev" target="_blank">app.webpeel.dev</a>.</p>

      <h3>Claude Desktop Config</h3>
      <p>Add to <code>~/Library/Application Support/Claude/claude_desktop_config.json</code> (macOS) or <code>%APPDATA%\Claude\claude_desktop_config.json</code> (Windows):</p>
      <pre><code class="language-json">{
  "mcpServers": {
    "webpeel": {
      "command": "npx",
      "args": ["-y", "webpeel", "--mcp"],
      "env": {
        "WEBPEEL_API_KEY": "YOUR-API-KEY"
      }
    }
  }
}</code></pre>

      <h3>Windsurf Config</h3>
      <pre><code class="language-json">{
  "mcpServers": {
    "webpeel": {
      "command": "npx",
      "args": ["-y", "webpeel", "--mcp"]
    }
  }
}</code></pre>
      <p>Set your API key via <code>npx webpeel login</code> or <code>WEBPEEL_API_KEY</code> environment variable.</p>

      <h3>Available MCP Tools</h3>
      <ul>
        <li><strong>webpeel_fetch</strong> — Fetch any URL → clean Markdown</li>
        <li><strong>webpeel_search</strong> — Search the web, get titles/URLs/snippets</li>
        <li><strong>webpeel_crawl</strong> — Crawl a site following links</li>
        <li><strong>webpeel_map</strong> — Discover all URLs on a domain</li>
        <li><strong>webpeel_extract</strong> — Extract structured data via CSS selectors or AI</li>
        <li><strong>webpeel_batch</strong> — Fetch multiple URLs concurrently</li>
        <li><strong>webpeel_agent</strong> — Autonomous web research agent (BYOK)</li>
      </ul>
    </main>
  </div>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-javascript.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-json.min.js"></script>
  <script src="../scripts/docs.js"></script>

  <footer class="docs-footer">
    <div class="footer-inner">
      <div class="footer-left">© 2026 WebPeel. Open source under AGPL-3.0.</div>
      <div class="footer-links">
        <a href="https://github.com/webpeel/webpeel">GitHub</a>
        <a href="https://app.webpeel.dev">Dashboard</a>
        <a href="/status">Status</a>
        <a href="/changelog">Changelog</a>
        <a href="/privacy">Privacy</a>
        <a href="/terms">Terms</a>
        <a href="/acceptable-use">Acceptable Use</a>
        <a href="https://github.com/webpeel/webpeel/issues">Support</a>
      </div>
    </div>
  </footer>
</body>
</html>
